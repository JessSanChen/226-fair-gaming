{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 09:40:54.055738: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from common_utils import compute_metrics\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_german\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
    "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "dataset_orig = load_preproc_data_german(['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of epoch:  (500, 11)\n"
     ]
    }
   ],
   "source": [
    "# split data into epochs, each with a different group of agents\n",
    "NUM_EPOCHS = 2\n",
    "dataset_orig_epochs = dataset_orig.split(NUM_EPOCHS, shuffle=True)\n",
    "print(\"Size of epoch: \", dataset_orig_epochs[0].features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO FAIRNESS\n",
    "# takes two epochs of data\n",
    "# trains on epoch_1, then uses model to classify epoch 2\n",
    "\n",
    "def no_fairness_train_and_classify(data_epoch_1, data_epoch_2):\n",
    "    # print out some labels, names, etc.\n",
    "    display(Markdown(\"#### No Fairness\"))\n",
    "    print(\"Epoch 1: \", data_epoch_1.features.shape)\n",
    "    print(\"Epoch 2: \",data_epoch_2.features.shape)\n",
    "\n",
    "    # train classifier on epoch 1\n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(data_epoch_1.features)\n",
    "    y_train = data_epoch_1.labels.ravel()\n",
    "    lmod = LogisticRegression(solver='liblinear')  # Solver specified to avoid future warnings\n",
    "    lmod.fit(X_train, y_train)\n",
    "\n",
    "    # classify epoch 2 agents\n",
    "    X_epoch2 = scale_orig.fit_transform(data_epoch_2.features)\n",
    "    y_epoch2_pred = lmod.predict(X_epoch2)\n",
    "    data_epoch_2_pred = data_epoch_2.copy(deepcopy=True)\n",
    "    data_epoch_2_pred.labels = y_epoch2_pred\n",
    "\n",
    "    # Evaluate fairness metrics on classification of epoch 2\n",
    "    metric_train = BinaryLabelDatasetMetric(data_epoch_2_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    \n",
    "    print(\"Training set: Difference in mean outcomes = {:.3f}\".format(metric_train.mean_difference()))\n",
    "\n",
    "    metric_test_aft = compute_metrics(data_epoch_2, data_epoch_2_pred, \n",
    "                unprivileged_groups, privileged_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_train_and_classify(data_epoch_1, data_epoch_2):\n",
    "    # print out some labels, names, etc.\n",
    "    display(Markdown(\"#### ROC Fairness\"))\n",
    "    print(\"Epoch 1: \", data_epoch_1.features.shape)\n",
    "    print(\"Epoch 2: \",data_epoch_2.features.shape)\n",
    "\n",
    "    # Metric used (should be one of allowed_metrics)\n",
    "    metric_name = \"Statistical parity difference\"\n",
    "\n",
    "    # Upper and lower bound on the fairness metric used\n",
    "    metric_ub = 0.05\n",
    "    metric_lb = -0.05\n",
    "\n",
    "    scale_orig = StandardScaler()\n",
    "\n",
    "    # need to first train a model to get predicted scores\n",
    "    X_train = scale_orig.fit_transform(data_epoch_1.features)\n",
    "    y_train = data_epoch_1.labels.ravel()\n",
    "    lmod = LogisticRegression(solver='liblinear')  # Solver specified to avoid future warnings\n",
    "    lmod.fit(X_train, y_train)\n",
    "\n",
    "    # indices of favorable label\n",
    "    pos_ind = np.where(lmod.classes_ == data_epoch_1.favorable_label)[0][0]\n",
    "\n",
    "    # data_epoch_1_pred contains PREDICTED SCORES\n",
    "    # use same epoch 1 data instead of separate validation\n",
    "    data_epoch_1_pred = data_epoch_1.copy(deepcopy=True)\n",
    "    X_train = scale_orig.transform(data_epoch_1_pred.features)\n",
    "    data_epoch_1_pred.scores = lmod.predict_proba(X_train)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "    ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "    ROC = ROC.fit(data_epoch_1, data_epoch_1_pred)\n",
    "\n",
    "    print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "    print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "\n",
    "    # Metrics for the transformed test set\n",
    "    data_epoch_2_pred = ROC.predict(data_epoch_2)\n",
    "\n",
    "    # Evaluate fairness metrics on classification of epoch 2\n",
    "    metric_train = BinaryLabelDatasetMetric(data_epoch_2_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    \n",
    "    print(\"Training set: Difference in mean outcomes = {:.3f}\".format(metric_train.mean_difference()))\n",
    "\n",
    "    metric_test_aft = compute_metrics(data_epoch_2, data_epoch_2_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### No Fairness"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  (500, 11)\n",
      "Epoch 2:  (500, 11)\n",
      "Training set: Difference in mean outcomes = -0.644\n",
      "Balanced accuracy = 0.5273\n",
      "Statistical parity difference = -0.6444\n",
      "Disparate impact = 0.3556\n",
      "Average odds difference = -0.6750\n",
      "Equal opportunity difference = -0.5833\n",
      "Theil index = 0.1283\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### ROC Fairness"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  (500, 11)\n",
      "Epoch 2:  (500, 11)\n",
      "Optimal classification threshold (with fairness constraints) = 0.6237\n",
      "Optimal ROC margin = 0.1613\n",
      "Training set: Difference in mean outcomes = -0.043\n",
      "Balanced accuracy = 1.0000\n",
      "Statistical parity difference = -0.0431\n",
      "Disparate impact = 0.9393\n",
      "Average odds difference = 0.0000\n",
      "Equal opportunity difference = 0.0000\n",
      "Theil index = 0.0000\n"
     ]
    }
   ],
   "source": [
    "no_fairness_train_and_classify(dataset_orig_epochs[0],dataset_orig_epochs[1])\n",
    "ROC_train_and_classify(dataset_orig_epochs[0],dataset_orig_epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "226",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
