{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 15:29:09.385729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from warnings import warn\n",
    "from collections import OrderedDict\n",
    "\n",
    "from aif360.datasets import GermanDataset, StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "# from common_utils import compute_metrics\n",
    "# from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        # import load_preproc_data_german\n",
    "from data_preproc_functions import load_preproc_data_german\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
    "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dataset_true, dataset_pred, \n",
    "                    unprivileged_groups, privileged_groups,\n",
    "                    disp = True):\n",
    "    \"\"\" Compute the key metrics \"\"\"\n",
    "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
    "                                                 dataset_pred, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    metrics = OrderedDict()\n",
    "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
    "                                             classified_metric_pred.true_negative_rate())\n",
    "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
    "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
    "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
    "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
    "    metrics[\"Theil index\"] = classified_metric_pred.theil_index()\n",
    "    metrics[\"Consistency (individual fairness)\"] = classified_metric_pred.consistency()\n",
    "    metrics[\"Generalized entropy index (unified individual and group fairness)\"] = classified_metric_pred.generalized_entropy_index()\n",
    "    \n",
    "    # if disp:\n",
    "    #     for k in metrics:\n",
    "    #         print(\"%s = %.4f\" % (k, metrics[k]))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dropped_data_german(protected_attributes=None):\n",
    "    dataset = load_preproc_data_german()\n",
    "    df = dataset.convert_to_dataframe()[0]\n",
    "    df = df[['age','credit_history=Other','savings=<500','credit']]\n",
    "\n",
    "    # Feature partitions\n",
    "    # XD_features = ['credit_history', 'savings', 'employment', 'sex', 'age']\n",
    "    D_features = ['sex', 'age'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['credit']\n",
    "    # X_features = list(set(XD_features)-set(D_features))\n",
    "    # print(X_features)\n",
    "    categorical_features = ['credit_history', 'savings', 'employment']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0],\n",
    "                              \"age\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
    "                                    \"age\": {1.0: 'Old', 0.0: 'Young'}}\n",
    "    new_german_data = StandardDataset(\n",
    "            df=df,\n",
    "            label_name=Y_features[0],\n",
    "            favorable_classes=[1],\n",
    "            protected_attribute_names=D_features,\n",
    "            privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "            instance_weights_name=None,\n",
    "            features_to_keep=['credit_history=Other','savings=<500']+Y_features+D_features,\n",
    "            metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "                    'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                    for x in D_features]})\n",
    "    \n",
    "    return new_german_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credit_history', 'savings', 'employment']\n",
      "0      A34\n",
      "1      A32\n",
      "2      A34\n",
      "3      A32\n",
      "4      A33\n",
      "      ... \n",
      "995    A32\n",
      "996    A32\n",
      "997    A32\n",
      "998    A32\n",
      "999    A34\n",
      "Name: credit_history, Length: 1000, dtype: object\n",
      "0          Other\n",
      "1      None/Paid\n",
      "2          Other\n",
      "3      None/Paid\n",
      "4          Delay\n",
      "         ...    \n",
      "995    None/Paid\n",
      "996    None/Paid\n",
      "997    None/Paid\n",
      "998    None/Paid\n",
      "999        Other\n",
      "Name: credit_history, Length: 1000, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'credit_history=Other', 'savings=<500']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset label"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credit']\n"
     ]
    }
   ],
   "source": [
    "# DROPPED DATA\n",
    "dataset_orig = load_dropped_data_german(['age'])\n",
    "\n",
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig.favorable_label, dataset_orig.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig.privileged_protected_attributes, \n",
    "      dataset_orig.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig.feature_names)\n",
    "display(Markdown(\"#### Dataset label\"))\n",
    "print(dataset_orig.label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of epoch:  (500, 3)\n"
     ]
    }
   ],
   "source": [
    "# split data into epochs, each with a different group of agents\n",
    "NUM_EPOCHS = 2\n",
    "dataset_orig_epochs = dataset_orig.split(NUM_EPOCHS, shuffle=True)\n",
    "print(\"Size of epoch: \", dataset_orig_epochs[0].features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO FAIRNESS\n",
    "# takes two epochs of data\n",
    "# trains on epoch_1, then uses model to classify epoch 2\n",
    "\n",
    "def no_fairness_train_and_classify(data_epoch_1, data_epoch_2):\n",
    "    # print out some labels, names, etc.\n",
    "    # display(Markdown(\"#### No Fairness\"))\n",
    "    # print(\"Epoch 1: \", data_epoch_1.features.shape)\n",
    "    # print(\"Epoch 2: \",data_epoch_2.features.shape)\n",
    "\n",
    "    # train classifier on epoch 1\n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(data_epoch_1.features)\n",
    "    y_train = data_epoch_1.labels.ravel()\n",
    "    lmod = LogisticRegression(solver='liblinear')  # Solver specified to avoid future warnings\n",
    "    lmod.fit(X_train, y_train)\n",
    "\n",
    "    # classify epoch 2 agents\n",
    "    X_epoch2 = scale_orig.fit_transform(data_epoch_2.features)\n",
    "    y_epoch2_pred = lmod.predict(X_epoch2)\n",
    "    data_epoch_2_pred = data_epoch_2.copy(deepcopy=True)\n",
    "    data_epoch_2_pred.labels = y_epoch2_pred\n",
    "\n",
    "    # print(\"Classifications: \", data_epoch_2_pred.labels)\n",
    "\n",
    "    # Evaluate fairness metrics on classification of epoch 2\n",
    "    metric_train = BinaryLabelDatasetMetric(data_epoch_2_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    \n",
    "    # print(\"Training set: Difference in mean outcomes = {:.3f}\".format(metric_train.mean_difference()))\n",
    "\n",
    "    metric_test_aft = compute_metrics(data_epoch_2, data_epoch_2_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # The estimated coefficients will all be around 1:\n",
    "    # print(lmod.coef_)\n",
    "    # print(data_epoch_1.feature_names)\n",
    "\n",
    "    return lmod, metric_test_aft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RW_train_and_classify(data_epoch_1, data_epoch_2):\n",
    "    # reweigh epoch 1 data\n",
    "    # display(Markdown(\"#### Reweighing Fairness\"))\n",
    "\n",
    "    RW1 = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "    RW1.fit(data_epoch_1)\n",
    "    dataset_transf_train1 = RW1.transform(data_epoch_1)\n",
    "\n",
    "    # train classifier on epoch 1\n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(dataset_transf_train1.features)\n",
    "    y_train = dataset_transf_train1.labels.ravel()\n",
    "    lmod = LogisticRegression(solver='liblinear')  # Solver specified to avoid future warnings\n",
    "    lmod.fit(X_train, y_train)\n",
    "\n",
    "    # reweigh epoch 2 data\n",
    "    RW2 = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "    RW2.fit(data_epoch_2)\n",
    "    dataset_transf_train2 = RW2.transform(data_epoch_2)\n",
    "\n",
    "    # classify epoch 2 agents\n",
    "    X_epoch2 = scale_orig.fit_transform(dataset_transf_train2.features)\n",
    "    y_epoch2_pred = lmod.predict(X_epoch2)\n",
    "    data_epoch_2_pred = dataset_transf_train2.copy(deepcopy=True)\n",
    "    data_epoch_2_pred.labels = y_epoch2_pred\n",
    "\n",
    "    # print(\"Classifications: \", data_epoch_2_pred.labels)\n",
    "\n",
    "    # Evaluate fairness metrics on classification of epoch 2\n",
    "    metric_train = BinaryLabelDatasetMetric(data_epoch_2_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    \n",
    "    # print(\"Training set: Difference in mean outcomes = {:.3f}\".format(metric_train.mean_difference()))\n",
    "\n",
    "    metric_test_aft = compute_metrics(dataset_transf_train2, data_epoch_2_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # The estimated coefficients will all be around 1:\n",
    "    # print(lmod.coef_)\n",
    "    # print(data_epoch_1.feature_names)\n",
    "\n",
    "    return lmod, metric_test_aft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.5174\n",
      "Statistical parity difference = -0.5259\n",
      "Disparate impact = 0.4741\n",
      "Average odds difference = -0.5627\n",
      "Equal opportunity difference = -0.4783\n",
      "Theil index = 0.1228\n",
      "Consistency (individual fairness) = 0.6844\n",
      "Generalized entropy index (unified individual and group fairness) = 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(solver='liblinear'),\n",
       " OrderedDict([('Balanced accuracy', 0.5173861892583119),\n",
       "              ('Statistical parity difference', -0.5258618925831203),\n",
       "              ('Disparate impact', 0.4741381074168797),\n",
       "              ('Average odds difference', -0.5626598465473145),\n",
       "              ('Equal opportunity difference', -0.4782608695652174),\n",
       "              ('Theil index', 0.12280542313403064),\n",
       "              ('Consistency (individual fairness)', array([0.6844])),\n",
       "              ('Generalized entropy index (unified individual and group fairness)',\n",
       "               0.09989050542231129)]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RW_train_and_classify(dataset_orig_epochs[0],dataset_orig_epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_train_and_classify(data_epoch_1, data_epoch_2):\n",
    "    # print out some labels, names, etc.\n",
    "    # display(Markdown(\"#### ROC Fairness\"))\n",
    "    # print(\"Epoch 1: \", data_epoch_1.features.shape)\n",
    "    # print(\"Epoch 2: \",data_epoch_2.features.shape)\n",
    "\n",
    "    # Metric used (should be one of allowed_metrics)\n",
    "    metric_name = \"Statistical parity difference\"\n",
    "\n",
    "    # Upper and lower bound on the fairness metric used\n",
    "    metric_ub = 0.05\n",
    "    metric_lb = -0.05\n",
    "\n",
    "    scale_orig = StandardScaler()\n",
    "\n",
    "    # need to first train a model to get predicted scores\n",
    "    X_train = scale_orig.fit_transform(data_epoch_1.features)\n",
    "    y_train = data_epoch_1.labels.ravel()\n",
    "    lmod = LogisticRegression(solver='liblinear')  # Solver specified to avoid future warnings\n",
    "    lmod.fit(X_train, y_train)\n",
    "\n",
    "    # indices of favorable label\n",
    "    pos_ind = np.where(lmod.classes_ == data_epoch_1.favorable_label)[0][0]\n",
    "\n",
    "    # data_epoch_1_pred contains PREDICTED SCORES\n",
    "    # use same epoch 1 data instead of separate validation\n",
    "    data_epoch_1_pred = data_epoch_1.copy(deepcopy=True)\n",
    "    X_train = scale_orig.transform(data_epoch_1_pred.features)\n",
    "    data_epoch_1_pred.scores = lmod.predict_proba(X_train)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "    ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "    ROC = ROC.fit(data_epoch_1, data_epoch_1_pred)\n",
    "\n",
    "    # print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "    # print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "\n",
    "    # Metrics for the transformed test set\n",
    "    data_epoch_2_pred = ROC.predict(data_epoch_2)\n",
    "\n",
    "    # Evaluate fairness metrics on classification of epoch 2\n",
    "    metric_train = BinaryLabelDatasetMetric(data_epoch_2_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    \n",
    "    # print(\"Training set: Difference in mean outcomes = {:.3f}\".format(metric_train.mean_difference()))\n",
    "\n",
    "    metric_test_aft = compute_metrics(data_epoch_2, data_epoch_2_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    return lmod, metric_test_aft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RW_ROC_train_and_classify(data_epoch_1, data_epoch_2):\n",
    "    # print out some labels, names, etc.\n",
    "    # display(Markdown(\"#### RW ROC Fairness\"))\n",
    "    # print(\"Epoch 1: \", data_epoch_1.features.shape)\n",
    "    # print(\"Epoch 2: \",data_epoch_2.features.shape)\n",
    "\n",
    "    # Metric used (should be one of allowed_metrics)\n",
    "    metric_name = \"Statistical parity difference\"\n",
    "\n",
    "    # Upper and lower bound on the fairness metric used\n",
    "    metric_ub = 0.05\n",
    "    metric_lb = -0.05\n",
    "\n",
    "    # reweigh epoch 1 data\n",
    "    RW1 = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "    RW1.fit(data_epoch_1)\n",
    "    dataset_transf_train1 = RW1.transform(data_epoch_1)\n",
    "\n",
    "    scale_orig = StandardScaler()\n",
    "\n",
    "    # need to first train a model to get predicted scores\n",
    "    X_train = scale_orig.fit_transform(dataset_transf_train1.features)\n",
    "    y_train = dataset_transf_train1.labels.ravel()\n",
    "    lmod = LogisticRegression(solver='liblinear')  # Solver specified to avoid future warnings\n",
    "    lmod.fit(X_train, y_train)\n",
    "\n",
    "    # indices of favorable label\n",
    "    pos_ind = np.where(lmod.classes_ == dataset_transf_train1.favorable_label)[0][0]\n",
    "\n",
    "    # data_epoch_1_pred contains PREDICTED SCORES\n",
    "    # use same epoch 1 data instead of separate validation\n",
    "    data_epoch_1_pred = dataset_transf_train1.copy(deepcopy=True)\n",
    "    X_train = scale_orig.transform(data_epoch_1_pred.features)\n",
    "    data_epoch_1_pred.scores = lmod.predict_proba(X_train)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "    ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "    ROC = ROC.fit(dataset_transf_train1, data_epoch_1_pred)\n",
    "\n",
    "    # print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "    # print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "\n",
    "    # reweigh epoch 1 data\n",
    "    RW2 = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "    RW2.fit(data_epoch_2)\n",
    "    dataset_transf_train2 = RW1.transform(data_epoch_2)\n",
    "\n",
    "    # Metrics for the transformed test set\n",
    "    data_epoch_2_pred = ROC.predict(dataset_transf_train2)\n",
    "\n",
    "    # Evaluate fairness metrics on classification of epoch 2\n",
    "    metric_train = BinaryLabelDatasetMetric(data_epoch_2_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    \n",
    "    # print(\"Training set: Difference in mean outcomes = {:.3f}\".format(metric_train.mean_difference()))\n",
    "\n",
    "    metric_test_aft = compute_metrics(dataset_transf_train2, data_epoch_2_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    return lmod, metric_test_aft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.5321\n",
      "Statistical parity difference = -0.5340\n",
      "Disparate impact = 0.4660\n",
      "Average odds difference = -0.5627\n",
      "Equal opportunity difference = -0.4783\n",
      "Theil index = 0.1228\n",
      "Consistency (individual fairness) = 0.6844\n",
      "Generalized entropy index (unified individual and group fairness) = 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(solver='liblinear'),\n",
       " OrderedDict([('Balanced accuracy', 0.5320531816116478),\n",
       "              ('Statistical parity difference', -0.5339805825242718),\n",
       "              ('Disparate impact', 0.46601941747572817),\n",
       "              ('Average odds difference', -0.5626598465473145),\n",
       "              ('Equal opportunity difference', -0.4782608695652174),\n",
       "              ('Theil index', 0.12280542313403064),\n",
       "              ('Consistency (individual fairness)', array([0.6844])),\n",
       "              ('Generalized entropy index (unified individual and group fairness)',\n",
       "               0.09989050542231129)]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_fairness_train_and_classify(dataset_orig_epochs[0],dataset_orig_epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 1.0000\n",
      "Statistical parity difference = -0.0606\n",
      "Disparate impact = 0.9171\n",
      "Average odds difference = 0.0000\n",
      "Equal opportunity difference = 0.0000\n",
      "Theil index = 0.0000\n",
      "Consistency (individual fairness) = 0.6844\n",
      "Generalized entropy index (unified individual and group fairness) = 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(solver='liblinear'),\n",
       " OrderedDict([('Balanced accuracy', 1.0),\n",
       "              ('Statistical parity difference', -0.06057567679929565),\n",
       "              ('Disparate impact', 0.9170739872782057),\n",
       "              ('Average odds difference', 0.0),\n",
       "              ('Equal opportunity difference', 0.0),\n",
       "              ('Theil index', 0.0),\n",
       "              ('Consistency (individual fairness)', array([0.6844])),\n",
       "              ('Generalized entropy index (unified individual and group fairness)',\n",
       "               0.0)]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC_train_and_classify(dataset_orig_epochs[0],dataset_orig_epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.5174\n",
      "Statistical parity difference = -0.5259\n",
      "Disparate impact = 0.4741\n",
      "Average odds difference = -0.5627\n",
      "Equal opportunity difference = -0.4783\n",
      "Theil index = 0.1228\n",
      "Consistency (individual fairness) = 0.6844\n",
      "Generalized entropy index (unified individual and group fairness) = 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(solver='liblinear'),\n",
       " OrderedDict([('Balanced accuracy', 0.5173861892583119),\n",
       "              ('Statistical parity difference', -0.5258618925831203),\n",
       "              ('Disparate impact', 0.4741381074168797),\n",
       "              ('Average odds difference', -0.5626598465473145),\n",
       "              ('Equal opportunity difference', -0.4782608695652174),\n",
       "              ('Theil index', 0.12280542313403064),\n",
       "              ('Consistency (individual fairness)', array([0.6844])),\n",
       "              ('Generalized entropy index (unified individual and group fairness)',\n",
       "               0.09989050542231129)]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RW_train_and_classify(dataset_orig_epochs[0],dataset_orig_epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 1.0000\n",
      "Statistical parity difference = 0.1436\n",
      "Disparate impact = 1.2091\n",
      "Average odds difference = 0.0000\n",
      "Equal opportunity difference = 0.0000\n",
      "Theil index = 0.0000\n",
      "Consistency (individual fairness) = 0.6844\n",
      "Generalized entropy index (unified individual and group fairness) = 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(solver='liblinear'),\n",
       " OrderedDict([('Balanced accuracy', 1.0),\n",
       "              ('Statistical parity difference', 0.14356030392477792),\n",
       "              ('Disparate impact', 1.2091303827020081),\n",
       "              ('Average odds difference', 0.0),\n",
       "              ('Equal opportunity difference', 0.0),\n",
       "              ('Theil index', 0.0),\n",
       "              ('Consistency (individual fairness)', array([0.6844])),\n",
       "              ('Generalized entropy index (unified individual and group fairness)',\n",
       "               0.0)]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RW_ROC_train_and_classify(dataset_orig_epochs[0],dataset_orig_epochs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_dataset_history(dataset_history, new_epoch, protected_attributes=None):\n",
    "    history_df = dataset_history.convert_to_dataframe()[0]\n",
    "    epoch_df = new_epoch.convert_to_dataframe()[0]\n",
    "\n",
    "    history_df = pd.concat([history_df,epoch_df])\n",
    "\n",
    "    # CONVERT DATASET\n",
    "    D_features = ['sex', 'age'] if protected_attributes is None else protected_attributes\n",
    "    Y_features = ['credit']\n",
    "    # X_features = list(set(XD_features)-set(D_features))\n",
    "    # print(X_features)\n",
    "    categorical_features = ['credit_history', 'savings', 'employment']\n",
    "\n",
    "    # privileged classes\n",
    "    all_privileged_classes = {\"sex\": [1.0],\n",
    "                              \"age\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
    "                                    \"age\": {1.0: 'Old', 0.0: 'Young'}}\n",
    "    result = StandardDataset(\n",
    "            df=history_df,\n",
    "            label_name=Y_features[0],\n",
    "            favorable_classes=[1],\n",
    "            protected_attribute_names=D_features,\n",
    "            privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "            instance_weights_name=None,\n",
    "            features_to_keep=['credit_history=Other','savings=<500']+Y_features+D_features,\n",
    "            metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "                    'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "                                    for x in D_features]})\n",
    "\n",
    "    aligned_dataset = dataset_history.align_datasets(result)\n",
    "\n",
    "    return aligned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of epoch:  (500, 3)\n",
      "Size of history:  (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# TEST THAT THE APPENDING WORKS\n",
    "\n",
    "history_data = dataset_orig_epochs[0]\n",
    "for epoch_ind in range(1,len(dataset_orig_epochs)):\n",
    "    # print(\"Size of epoch: \", dataset_orig_epochs[epoch_ind].features.shape)\n",
    "    history_data = append_dataset_history(history_data,dataset_orig_epochs[epoch_ind], [\"age\"])\n",
    "    # print(\"Size of history: \", history_data.features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit_history=Other is the meaningful features\n",
    "MEANINGFUL_FEATURE_IND = 1\n",
    "\n",
    "ADV_MOD_PROB_MEAN = 0.8\n",
    "ADV_MOD_PROB_STD = 0.05\n",
    "DIS_MOD_PROB_MEAN = 0.5\n",
    "DIS_MOD_PROB_STD = 0.2\n",
    "MOD_THRESHOLD = 0.7\n",
    "\n",
    "def strategizing_agents(data_epoch, model, FAVORABLE_LABEL_MOD_THRESHOLD,PER_EPOCH_PENALTY,MODIFY_GAIN):\n",
    "    # advantaged agents have higher distribution of flipping coin to modify\n",
    "    # if successful, can choose which feature to modify\n",
    "\n",
    "    # get scaled data from agent\n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(data_epoch.features)\n",
    "    y_train = data_epoch.labels.ravel()\n",
    "\n",
    "    # FAVORABLE_LABEL_MOD_THRESHOLD = 1\n",
    "    # PER_EPOCH_PENALTY = 1\n",
    "    # MODIFY_GAIN = 1\n",
    "\n",
    "    unfavorable_classification_count = 0\n",
    "    mod_count = 0\n",
    "    new_classication_count = 0\n",
    "    adv_agent_new_classificaton_count = 0\n",
    "    adv_agent_count = 0\n",
    "    meaningful_mod_count = 0\n",
    "    favorable_label_change_count = 0\n",
    "    unfavorable_label_change_count = 0\n",
    "\n",
    "\n",
    "    for agent_ind in range(data_epoch.features.shape[0]):\n",
    "        # print(f\"Agent {agent_ind}\")\n",
    "        # print(X_train[agent_ind])\n",
    "        if X_train[agent_ind][0] > 0:\n",
    "            adv_agent_count +=1\n",
    "\n",
    "        # penalize everyone by the meaningful feature (credit history)\n",
    "        # subtract by a standard deviation\n",
    "        for feat_ind in range(1,data_epoch.features.shape[1]):\n",
    "            X_train[agent_ind][feat_ind] -= PER_EPOCH_PENALTY\n",
    "        \n",
    "        # original classification\n",
    "        agent_classification = model.predict([X_train[agent_ind]])\n",
    "        # print(\"classify: \",agent_classification)\n",
    "        \n",
    "        # if bad credit, agent will try to modify feature\n",
    "        # advantaged agent more likely to be able to modify\n",
    "        if agent_classification == 2: # bad credit\n",
    "            unfavorable_classification_count+=1\n",
    "            # print(\"bad credit\")\n",
    "            # under 25, disadvantaged\n",
    "            if data_epoch.unprivileged_protected_attributes[0][0] == 0: \n",
    "                prob_change_feature = np.random.normal(DIS_MOD_PROB_MEAN,DIS_MOD_PROB_STD)\n",
    "            else: \n",
    "                prob_change_feature = np.random.normal(ADV_MOD_PROB_MEAN,ADV_MOD_PROB_STD)\n",
    "        else:\n",
    "            prob_change_feature = 0\n",
    "        \n",
    "        # if allowed to modify\n",
    "        if prob_change_feature > MOD_THRESHOLD:\n",
    "            mod_count += 1\n",
    "            # randomly iterate through features to modify\n",
    "            # if successfully re-classifies, then exit out\n",
    "            feature_indices = list(range(1,len(data_epoch.feature_names)))\n",
    "            random.shuffle(feature_indices)\n",
    "\n",
    "            for feature_ind in feature_indices:\n",
    "                # print(data_history.feature_names[feature_ind])\n",
    "                # if data_history.feature_names[feature_ind] is not data_history.protected_attribute_names[0]:\n",
    "                #     if X_train[agent_ind][feature_ind] < 0:\n",
    "                \n",
    "                # improve one of the features\n",
    "                try_new_train = list(X_train[agent_ind])\n",
    "                try_new_train[feature_ind] = min(1.5,try_new_train[feature_ind]+MODIFY_GAIN)\n",
    "                new_classify = model.predict([try_new_train])\n",
    "\n",
    "                # check if feature modification did in help improve classification\n",
    "                if new_classify < agent_classification:\n",
    "                    # store as the X_train\n",
    "                    data_epoch.features[agent_ind] = try_new_train \n",
    "\n",
    "                    # counters\n",
    "                    new_classication_count+=1\n",
    "                    if X_train[agent_ind][0] > 0:\n",
    "                        adv_agent_new_classificaton_count+=1\n",
    "                    if feature_ind == MEANINGFUL_FEATURE_IND:\n",
    "                        meaningful_mod_count += 1\n",
    "                    \n",
    "                    # print(new_classify)\n",
    "                    # print(try_new_train)\n",
    "\n",
    "                    # if classification has been improved, leave for-loop\n",
    "                    break\n",
    "    \n",
    "        # change the true labels based on feature mod; important for future training\n",
    "        original_label = int(data_epoch.labels[agent_ind])\n",
    "        # print(\"original label: \", original_label)\n",
    "        # print(\"new meaningful feature val: \", data_epoch.features[agent_ind][MEANINGFUL_FEATURE_IND])\n",
    "        if data_epoch.features[agent_ind][MEANINGFUL_FEATURE_IND] > FAVORABLE_LABEL_MOD_THRESHOLD:\n",
    "            data_epoch.labels[agent_ind] = 1\n",
    "            if data_epoch.labels[agent_ind] != original_label:\n",
    "                favorable_label_change_count += 1\n",
    "        else: \n",
    "            data_epoch.labels[agent_ind] = 2\n",
    "            if data_epoch.labels[agent_ind] != original_label:\n",
    "                unfavorable_label_change_count += 1\n",
    "\n",
    "    # print(\"adv_agent_count\", adv_agent_count)\n",
    "    # print(\"unfavorable_classification_count: \",unfavorable_classification_count)\n",
    "    # print(\"mod_count: \", mod_count)\n",
    "    # print(\"new_classication_count: \", new_classication_count)\n",
    "    # print(\"adv_agent_new_classificaton_count: \",adv_agent_new_classificaton_count)\n",
    "    # print(\"meaningful_mod_count: \",meaningful_mod_count)\n",
    "    # print(\"favorable_label_change_count: \",favorable_label_change_count)\n",
    "    # print(\"unfavorable_label_change_count: \",unfavorable_label_change_count)\n",
    "\n",
    "    return data_epoch\n",
    "\n",
    "    \n",
    "# SEPARATELY NEED TO RETRAIN MODEL AND APPEND HISTORY\n",
    "    \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each step uses a classifier\n",
    "# strategizes next epoch \n",
    "# show fairness\n",
    "def iterative_gaming_sim(fair_algo, gaming):\n",
    "    dataset_orig = load_dropped_data_german(['age'])\n",
    "\n",
    "    privileged_groups = [{'age': 1}]\n",
    "    unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "    NUM_TRIALS = 10\n",
    "    NUM_EPOCHS = 4\n",
    "\n",
    "    avg_metrics = [{\n",
    "        \"Balanced accuracy\":0,\n",
    "        \"Statistical parity difference\":0,\n",
    "        \"Disparate impact\":0,\n",
    "        \"Equal opportunity difference\":0,\n",
    "        \"Consistency (individual fairness)\":0\n",
    "    }]*(NUM_EPOCHS-1)\n",
    "    \n",
    "    for trial in range(NUM_TRIALS):\n",
    "        # split data into epochs, each with a different group of agents\n",
    "        \n",
    "        epochs = dataset_orig.split(NUM_EPOCHS, shuffle=True)\n",
    "        # print(\"Size of epoch: \", dataset_orig_epochs[0].features.shape)\n",
    "        \n",
    "        nfair_ngame_history = epochs[0]\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS-1):\n",
    "            # display(Markdown(f\"### Epoch {epoch}/{NUM_EPOCHS}\"))\n",
    "            if fair_algo == \"None\":\n",
    "                model,metrics = no_fairness_train_and_classify(nfair_ngame_history,epochs[epoch+1])\n",
    "            elif fair_algo == \"RW\":\n",
    "                model,metrics = RW_train_and_classify(nfair_ngame_history,epochs[epoch+1])\n",
    "            elif fair_algo == \"ROC\":\n",
    "                model,metrics = ROC_train_and_classify(nfair_ngame_history,epochs[epoch+1])\n",
    "            elif fair_algo == \"RW ROC\":\n",
    "                model,metrics = RW_ROC_train_and_classify(nfair_ngame_history,epochs[epoch+1])\n",
    "            else:\n",
    "                print(\"invalid fairness algo\")\n",
    "            \n",
    "            if gaming:\n",
    "                next_epoch = strategizing_agents(epochs[epoch+1],model,1,1,1)\n",
    "            else:\n",
    "                next_epoch = epochs[epoch+1]\n",
    "            nfair_ngame_history = append_dataset_history(nfair_ngame_history, next_epoch, ['age'])\n",
    "\n",
    "            avg_metrics[epoch][\"Balanced accuracy\"] += metrics[\"Balanced accuracy\"]\n",
    "            avg_metrics[epoch][\"Statistical parity difference\"] += metrics[\"Statistical parity difference\"]\n",
    "            avg_metrics[epoch][\"Disparate impact\"] += metrics[\"Disparate impact\"]\n",
    "            avg_metrics[epoch][\"Equal opportunity difference\"] += metrics[\"Equal opportunity difference\"]\n",
    "            avg_metrics[epoch][\"Consistency (individual fairness)\"] += metrics[\"Consistency (individual fairness)\"]\n",
    "\n",
    "            # print(avg_metrics[epoch-1])\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS-1):\n",
    "        avg_metrics[epoch][\"Balanced accuracy\"] /= NUM_TRIALS\n",
    "        avg_metrics[epoch][\"Statistical parity difference\"] /= NUM_TRIALS\n",
    "        avg_metrics[epoch][\"Disparate impact\"] /= NUM_TRIALS\n",
    "        avg_metrics[epoch][\"Equal opportunity difference\"] /= NUM_TRIALS\n",
    "        avg_metrics[epoch][\"Consistency (individual fairness)\"] /= NUM_TRIALS\n",
    "\n",
    "    for epoch in range(len(avg_metrics)):\n",
    "        display(Markdown(f\"### Epoch {epoch} fairness metrics\"))\n",
    "        for k in avg_metrics[epoch]:\n",
    "            print(\"%s = %.4f\" % (k, avg_metrics[epoch][k]))\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credit_history', 'savings', 'employment']\n",
      "0      A34\n",
      "1      A32\n",
      "2      A34\n",
      "3      A32\n",
      "4      A33\n",
      "      ... \n",
      "995    A32\n",
      "996    A32\n",
      "997    A32\n",
      "998    A32\n",
      "999    A34\n",
      "Name: credit_history, Length: 1000, dtype: object\n",
      "0          Other\n",
      "1      None/Paid\n",
      "2          Other\n",
      "3      None/Paid\n",
      "4          Delay\n",
      "         ...    \n",
      "995    None/Paid\n",
      "996    None/Paid\n",
      "997    None/Paid\n",
      "998    None/Paid\n",
      "999        Other\n",
      "Name: credit_history, Length: 1000, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 0 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0155\n",
      "Statistical parity difference = -0.0044\n",
      "Disparate impact = nan\n",
      "Equal opportunity difference = -0.0041\n",
      "Consistency (individual fairness) = 0.0190\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 1 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0155\n",
      "Statistical parity difference = -0.0044\n",
      "Disparate impact = nan\n",
      "Equal opportunity difference = -0.0041\n",
      "Consistency (individual fairness) = 0.0190\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 2 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0155\n",
      "Statistical parity difference = -0.0044\n",
      "Disparate impact = nan\n",
      "Equal opportunity difference = -0.0041\n",
      "Consistency (individual fairness) = 0.0190\n",
      "['credit_history', 'savings', 'employment']\n",
      "0      A34\n",
      "1      A32\n",
      "2      A34\n",
      "3      A32\n",
      "4      A33\n",
      "      ... \n",
      "995    A32\n",
      "996    A32\n",
      "997    A32\n",
      "998    A32\n",
      "999    A34\n",
      "Name: credit_history, Length: 1000, dtype: object\n",
      "0          Other\n",
      "1      None/Paid\n",
      "2          Other\n",
      "3      None/Paid\n",
      "4          Delay\n",
      "         ...    \n",
      "995    None/Paid\n",
      "996    None/Paid\n",
      "997    None/Paid\n",
      "998    None/Paid\n",
      "999        Other\n",
      "Name: credit_history, Length: 1000, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/Users/jessicachen/opt/anaconda3/envs/226/lib/python3.8/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 0 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0152\n",
      "Statistical parity difference = -0.0039\n",
      "Disparate impact = nan\n",
      "Equal opportunity difference = -0.0036\n",
      "Consistency (individual fairness) = 0.0187\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 1 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0152\n",
      "Statistical parity difference = -0.0039\n",
      "Disparate impact = nan\n",
      "Equal opportunity difference = -0.0036\n",
      "Consistency (individual fairness) = 0.0187\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 2 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0152\n",
      "Statistical parity difference = -0.0039\n",
      "Disparate impact = nan\n",
      "Equal opportunity difference = -0.0036\n",
      "Consistency (individual fairness) = 0.0187\n",
      "['credit_history', 'savings', 'employment']\n",
      "0      A34\n",
      "1      A32\n",
      "2      A34\n",
      "3      A32\n",
      "4      A33\n",
      "      ... \n",
      "995    A32\n",
      "996    A32\n",
      "997    A32\n",
      "998    A32\n",
      "999    A34\n",
      "Name: credit_history, Length: 1000, dtype: object\n",
      "0          Other\n",
      "1      None/Paid\n",
      "2          Other\n",
      "3      None/Paid\n",
      "4          Delay\n",
      "         ...    \n",
      "995    None/Paid\n",
      "996    None/Paid\n",
      "997    None/Paid\n",
      "998    None/Paid\n",
      "999        Other\n",
      "Name: credit_history, Length: 1000, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 0 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0300\n",
      "Statistical parity difference = -0.0043\n",
      "Disparate impact = 0.0241\n",
      "Equal opportunity difference = 0.0000\n",
      "Consistency (individual fairness) = 0.0185\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 1 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0300\n",
      "Statistical parity difference = -0.0043\n",
      "Disparate impact = 0.0241\n",
      "Equal opportunity difference = 0.0000\n",
      "Consistency (individual fairness) = 0.0185\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 2 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0300\n",
      "Statistical parity difference = -0.0043\n",
      "Disparate impact = 0.0241\n",
      "Equal opportunity difference = 0.0000\n",
      "Consistency (individual fairness) = 0.0185\n",
      "['credit_history', 'savings', 'employment']\n",
      "0      A34\n",
      "1      A32\n",
      "2      A34\n",
      "3      A32\n",
      "4      A33\n",
      "      ... \n",
      "995    A32\n",
      "996    A32\n",
      "997    A32\n",
      "998    A32\n",
      "999    A34\n",
      "Name: credit_history, Length: 1000, dtype: object\n",
      "0          Other\n",
      "1      None/Paid\n",
      "2          Other\n",
      "3      None/Paid\n",
      "4          Delay\n",
      "         ...    \n",
      "995    None/Paid\n",
      "996    None/Paid\n",
      "997    None/Paid\n",
      "998    None/Paid\n",
      "999        Other\n",
      "Name: credit_history, Length: 1000, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 0 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0300\n",
      "Statistical parity difference = -0.0023\n",
      "Disparate impact = 0.0270\n",
      "Equal opportunity difference = 0.0000\n",
      "Consistency (individual fairness) = 0.0184\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 1 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0300\n",
      "Statistical parity difference = -0.0023\n",
      "Disparate impact = 0.0270\n",
      "Equal opportunity difference = 0.0000\n",
      "Consistency (individual fairness) = 0.0184\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch 2 fairness metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.0300\n",
      "Statistical parity difference = -0.0023\n",
      "Disparate impact = 0.0270\n",
      "Equal opportunity difference = 0.0000\n",
      "Consistency (individual fairness) = 0.0184\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "ng_nf_results= iterative_gaming_sim(\"None\", True)\n",
    "# with open('ng_nf_results.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "#     w = csv.DictWriter(f, ng_nf_results.keys())\n",
    "#     w.writeheader()\n",
    "#     w.writerow(ng_nf_results)\n",
    "\n",
    "rw_results = iterative_gaming_sim(\"RW\", True)\n",
    "# with open('rw_results.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "#     w = csv.DictWriter(f, rw_results.keys())\n",
    "#     w.writeheader()\n",
    "#     w.writerow(rw_results)\n",
    "\n",
    "roc_results = iterative_gaming_sim(\"ROC\", True)\n",
    "# with open('roc_results.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "#     w = csv.DictWriter(f, roc_results.keys())\n",
    "#     w.writeheader()\n",
    "#     w.writerow(roc_results)\n",
    "\n",
    "rw_roc_results = iterative_gaming_sim(\"RW ROC\", True)\n",
    "# with open('rw_roc_results.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "#     w = csv.DictWriter(f, rw_roc_results.keys())\n",
    "#     w.writeheader()\n",
    "#     w.writerow(rw_roc_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "226",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
